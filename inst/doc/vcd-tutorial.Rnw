\documentclass{Z}
%% need no \usepackage{Sweave}
\usepackage{bm}

% math stuff
\newcommand*{\given}{\ensuremath{\, | \,}}
\renewcommand*{\vec}[1]{\ensuremath{\bm{#1}}}
\newcommand{\mat}[1]{\ensuremath{\bm{#1}}}
\newcommand{\trans}{\ensuremath{^\mathsf{T}}}
\newcommand{\diag}[1]{\ensuremath{\mathrm{diag} (#1)}}
\def\binom#1#2{{#1 \choose #2}}%
\newcommand{\implies}{ \ensuremath{\mapsto} }

\newenvironment{equation*}{\displaymath}{\enddisplaymath}%

\newcommand{\tabref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\loglin}{loglinear }

%\usepackage{thumbpdf}

% page dimensions
\addtolength{\hoffset}{-1.5cm}
\addtolength{\textwidth}{3cm}
\addtolength{\voffset}{-1cm}
\addtolength{\textheight}{2cm}


%% almost as usual
\author{Michael Friendly\\York University, Toronto}
\title{Tutorial: Working with categorical data with \proglang{R} and the \pkg{vcd} package}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Michael Friendly} %% comma-separated
\Shorttitle{vcd tutorial} %% a short title (if necessary)
\Plaintitle{Tutorial: Working with categorical data with R and the vcd package}

%% an abstract and keywords
\Abstract{
This tutorial describes the creation of frequency and contingency tables
from categorical variables, along with tests of independence, measures
of association, and methods for graphically displaying results. 
The framework is provided by the \proglang{R} package \pkg{vcd},
but other packages are used to help with various tasks.
}

\Keywords{contingency tables, mosaic plots, sieve plots, 
categorical data, independence, conditional independence,
\proglang{R}}
\Plainkeywords{contingency tables, mosaic plots, 
  sieve plots, categorical data, independence, 
  conditional independence, R}

%\SweaveOpts{engine=R,eps=TRUE,height=6,width=7,results=hide,fig=FALSE,echo=TRUE}
\SweaveOpts{engine=R,height=6,width=7,results=hide,fig=FALSE,echo=TRUE}
\SweaveOpts{prefix.string=fig/vcd-tut}
\setkeys{Gin}{width=0.7\textwidth}
%\VignetteIndexEntry{Tutorial: Working with categorical data with R and the vcd package}
%\VignetteDepends{vcd,gmodels,ca}
%\VignetteKeywords{contingency tables, mosaic plots, sieve plots, categorical data, independence, conditional independence, R}
%\VignettePackage{vcdExtra}

<<preliminaries,echo=FALSE,results=hide>>=
set.seed(1071)
#library(vcd)
library(vcdExtra)
#data(Titanic)
data(HairEyeColor)
data(PreSex)
data(Arthritis)
art <- xtabs(~Treatment + Improved, data = Arthritis)
@

\newcommand{\var}[1]{\textit{\texttt{#1}}}
\newcommand{\data}[1]{\texttt{#1}}
\newcommand{\class}[1]{\textsf{#1}}
%% \code without `-' ligatures
\def\nohyphenation{\hyphenchar\font=-1 \aftergroup\restorehyphenation}
\def\restorehyphenation{\hyphenchar\font=`-}
{\catcode`\-=\active%
  \global\def\code{\bgroup%
    \catcode`\-=\active \let-\codedash%
    \Rd@code}}
\def\codedash{-\discretionary{}{}{}}
\def\Rd@code#1{\texttt{\nohyphenation#1}\egroup}

\newcommand{\codefun}[1]{\code{#1()}}


%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\SweaveOpts{keep.source=TRUE}

\begin{document}

%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section[Introduction]{Introduction}
%% Note: If there is markup in \(sub)section, then it has to be escape as above.


This tutorial, part of the \pkg{vcdExtra} package,
 describes the creation of frequency and contingency tables
from categorical variables, along with tests of independence, measures
of association, and methods for graphically displaying results.
It borrows structure and some ideas from from Robert Kabakoff's \emph{Quick-R} web page,
\url{http://www.statmethods.net/stats/frequencies.html}.

There is much more to the analysis of categorical data than is described here,
where the emphasis is on cross-tabulated tables of frequencies (``contingency tables''),
statistical tests, associated \loglin\ models, and visualization of \emph{how}
variables are related.

A more general treatment of graphical methods for categorical data is contained
in my book, \emph{Visualizing Categorical Data} \citep{vcd:Friendly:2000}, for which
\pkg{vcd} is a partial \proglang{R} companion, covering topics not otherwise
available in \proglang{R}.  On the other hand, the implementation of graphical
methods in \pkg{vcd} is more general in many respects than what I provided in
\proglang{SAS}.

A more complete theoretical description of these statistical
methods is provided in Agresti's \citeyearpar{vcd:Agresti:2002}
\emph{Categorical Data Analysis}. For this, see
the \proglang{Splus/R} companion by Laura Thompson,
\url{https://home.comcast.net/~lthompson221/Splusdiscrete2.pdf}.



\section{Creating and manipulating frequency tables}

\proglang{R} provides many methods for creating frequency and contingency tables. Several are
described below. In the examples below, we use some real examples and some anonymous
ones, where the variables \code{A}, \code{B}, and \code{C}  represent
categorical variables, and \code{X} represents an arbitrary \proglang{R} data object.

The first thing you need to know is that categorical data can be represented in
three different forms in \proglang{R}, and it is sometimes necessary to convert
from one form to another, for carrying out statistical tests, fitting models
or visualizing the results.  Once a data object exists in \proglang{R}, 
you can examine its structure with
the \codefun{str} function. 
 
\begin{description}
  \item[case form] a data frame containing individual observations, with one or
  more factors, used as the classifying variables. In case form, there may also
  be numeric covariates. 
  The total number of observations
  is \code{nrow(X)}.
  	
\emph{Example}: The \data{Arthritis} data is available in case form in the \pkg{vcd} package. 
There are two explanatory factors: \code{Treatment} and \code{Sex}. \code{Age}
is a covariate, and \code{Improved} is the response--- an ordered factor,
with levels 
\Sexpr{paste(levels(Arthritis$Improved),collapse=' < ')}.  Excluding \code{Age}, we have
a $2 \times 2 \times 3$ contingency table for \code{Treatment}, \code{Sex} and \code{Improved}.
%\code{"None" < "Some" < "Marked"}.
<<case-form,results=verbatim>>=
str(Arthritis)      # show the structure
Arthritis[1:5,]     # first 5 observations
@
  
  \item[frequency form] a data frame containing one or more factors, and a frequency 
  variable, often called \code{Freq} or \code{count}.  The total number of observations
  is \code{sum(X[,"Freq"])} or some equivalent form.

\emph{Example}: For small frequency tables, it is often convenient to enter them in frequency form
using \codefun{expand.grid} for the factors and \codefun{c} to list the counts in a vector.
The example below, from \cite{vcd:Agresti:2002} gives results for the 1991 General Social Survey,
with respondents classified by sex and party identification.
<<frequency-form,results=verbatim>>=
# Agresti (2002), table 3.11, p. 106
GSS <- data.frame(
  expand.grid(sex=c("female", "male"), 
              party=c("dem", "indep", "rep")),
  count=c(279,165,73,47,225,191))
GSS
str(GSS)
sum(GSS$count)
@

  \item[table form]  a matrix, array or table object, whose elements are the frequencies
  in an $n$-way table.  The variable names (factors) and their levels are given by
  \code{dimnames(X)}. The total number of observations
  is \code{sum(X)}.  The number of dimensions of the table is \code{length(dimnames(X))},
  and the table sizes are given by \code{sapply(dimnames(X), length)}.
  	
\emph{Example}: The \data{HairEyeColor} is stored in table form in \pkg{vcd}.  
<<table-form1,results=verbatim>>=
str(HairEyeColor)                      # show the structure
sum(HairEyeColor)                      # number of cases
sapply(dimnames(HairEyeColor), length) # table dimension sizes
@

\emph{Example}: Enter frequencies in a matrix, and assign \code{dimnames},
giving the variable names and category labels.  Note that, by default,
\codefun{matrix} uses the elements supplied by \emph{columns} in the
result, unless you specify \code{byrow=TRUE}.
<<table-form2,results=verbatim>>=
## A 4 x 4 table  Agresti (2002, Table 2.8, p. 57) Job Satisfaction
JobSat <- matrix(c(1,2,1,0, 3,3,6,1, 10,10,14,9, 6,7,12,11), 4, 4)
dimnames(JobSat) = list(income=c("< 15k", "15-25k", "25-40k", "> 40k"),
                satisfaction=c("VeryD", "LittleD", "ModerateS", "VeryS"))
JobSat
@
\data{JobSat} is a matrix, not an object of \code{class("table")}, and some functions
are happier with tables than matrices.
You can coerce it to a table with \codefun{as.table},
<<table-form3,results=verbatim>>=
JobSat <- as.table(JobSat)
str(JobSat)
@

\end{description}

\subsection{Ordered factors and reordered tables}
In table form, the values of the table factors are ordered by their position in the table.
Thus in the \data{JobSat} data, both \code{income} and \code{satisfaction} represent ordered
factors, and the \emph{positions} of the values in the rows and columns reflects their
ordered nature.

Yet, for analysis, there are time when you need \emph{numeric} values for the levels
of ordered factors in a table, e.g., to treat a factor as a quantitative variable.
In such cases, you can simply re-assign the \code{dimnames} attribute of the table
variables.  For example, here, we assign numeric values to \code{income} as the middle of their
ranges, and treat \code{satisfaction} as equally spaced with integer scores.

<<relevel,results=hide,eval=FALSE>>=
dimnames(JobSat)$income<-c(7.5,20,32.5,60)
dimnames(JobSat)$satisfaction<-1:4
@

For the  \data{HairEyeColor} data, hair color and eye color are ordered arbitrarily.
For visualizing the data using mosaic plots and other methods described below, it 
turns out to be more useful to assure that both hair color and eye color are
ordered from dark to light.
Hair colors are actually ordered this way already, and it is easiest to re-order
eye colors by indexing. Again \codefun{str} is your friend.

<<reorder1,results=verbatim>>=
HairEyeColor <- HairEyeColor[, c(1,3,4,2), ]
str(HairEyeColor)
@
This is also the order for both hair color and eye color shown in 
the result of a correspondence analysis (\figref{fig:ca-haireye}) below.

With data in  case form or frequency form, when you have ordered factors
represented with character values, you must ensure that they are treated
as ordered in \proglang{R}.%
\footnote{In \proglang{SAS}, many procedures offer the option
	\code{order = data | internal | formatted} to allow character values
	to be ordered according to (a) their order in the data set, (b)
	sorted internal value, or (c) sorted formatted representation
	provided by a \proglang{SAS} format.
}

Imagine that the \data{Arthritis} data was read from a text file.  
By default the \code{Improved} will be ordered alphabetically:
\code{Marked},
\code{None},
\code{Some}--- not what we want.  In this case, the function
\codefun{ordered} (and others) can be useful. 

<<reorder2,echo=TRUE,eval=FALSE>>=
Arthritis <- read.csv("arthritis.txt",header=TRUE)
Arthritis$Improved <- ordered(Arthritis$Improved, levels=c("None", "Some", "Marked"))
@

With this order of  \code{Improved}, the response in this data,
a mosaic display of \code{Treatment} and \code{Improved} (\figref{fig:arthritis})shows a clearly
interpretable pattern.
\setkeys{Gin}{width=0.7\textwidth}
\begin{figure}[htb]
\begin{center}
<<Arthritis,fig=TRUE,echo=FALSE,height=6,width=7,results=hide>>=
mosaic(art, gp = shading_max, split_vertical = TRUE, main="Arthritis: [Treatment] [Improved]")
@
\caption{Mosaic plot for the \data{Arthritis} data, showing the marginal model of independence
	for Treatment and Improved.  Age, a covariate, and Sex are ignored here.}
\label{fig:arthritis}
\end{center}
\end{figure}

Finally, there are situations where, particularly for display purposes, you
want to re-order the \emph{dimensions} of an $n$-way table, or change the
labels for the variables or levels.
This is easy when the data are in table form: \codefun{aperm} permutes
the dimensions, and assigning to \code{names} and \code{dimnames}
changes variable names and level labels respectively.
We will use the following version of \data{UCBAdmissions} in
\secref{sec:mantel} below.%
\footnote{
Changing \code{Admit} to \code{Admit?} might be useful for display purposes, but it
dangerous--- because it is then
difficult to use that variable name in a model formula.
}
<<reorder3,results=verbatim>>=
UCB <- aperm(UCBAdmissions, c(2, 1, 3))
dimnames(UCB)[[2]] <- c("Yes", "No")
names(dimnames(UCB)) <- c("Sex", "Admit?", "Department")
ftable(UCB)
@

\subsection[structable]{\codefun{structable}}
For 3-way and larger tables
the \codefun{structable} function in \pkg{vcd} provides a convenient and flexible tabular display.
The variables assigned to the rows and columns of a two-way display to be specified
by a model formula.
<<structable,results=verbatim>>=
structable(HairEyeColor)                   # show the table: default
structable(Hair+Sex ~ Eye, HairEyeColor)   # specify col ~ row variables
@
It also returns an object of class \code{"structable"} which may be plotted with 
\codefun{mosaic} (not shown here).
<<structable1,eval=FALSE>>=
HSE < - structable(Hair+Sex ~ Eye, HairEyeColor)   # save structable object
mosaic(HSE)                                        # plot it
@

\subsection[table and friends]{\codefun{table} and friends}\label{sec:table}

You  can  generate frequency  tables from factor variables  using the  \codefun{table} function,  tables  of
proportions using  the \codefun{prop.table} function,  and marginal  frequencies using
\codefun{margin.table}.

<<setup>>=
 n=500
 A <- factor(sample(c("a1","a2"), n, rep=TRUE))
 B <- factor(sample(c("b1","b2"), n, rep=TRUE))
 C <- factor(sample(c("c1","c2"), n, rep=TRUE))
 mydata <- data.frame(A,B,C)
@

<<table-ex1>>=
# 2-Way Frequency Table
attach(mydata)
mytable <- table(A,B)   # A will be rows, B will be columns
mytable                 # print table

margin.table(mytable, 1) # A frequencies (summed over B)
margin.table(mytable, 2) # B frequencies (summed over A)

prop.table(mytable)    # cell percentages
prop.table(mytable, 1) # row percentages
prop.table(mytable, 2) # column percentages
@

\codefun{table} can  also  generate  multidimensional  tables  based  on  3  or  more
categorical variables. In  this case, use  the \codefun{ftable}  function to print  the
results more attractively.

<<table-ex2>>=
# 3-Way Frequency Table
mytable <- table(A, B, C)
ftable(mytable)
@

Table ignores missing values. To include \code{NA} as a category in counts, include the
table option  \code{exclude=NULL} if  the variable  is a  vector. If  the variable is a
factor you  have to  create a  new factor  using \code{newfactor  <- factor(oldfactor,
exclude=NULL)}. 

\subsection{xtabs}\label{sec:xtabs}

The \codefun{xtabs} function allows you to create crosstabulations using formula style input.

<<xtabs-ex1>>=
# 3-Way Frequency Table
mytable <- xtabs(~A+B+C, data=mydata)
ftable(mytable)    # print table
summary(mytable)   # chi-square test of indepedence
@

If a variable is included on the left side of the formula, it is assumed to be a
vector  of  frequencies  (useful  if  the  data  have  already  been tabulated).

<<xtabs-ex2,results=verbatim>>=
(GSStab <- xtabs(count ~ sex + party, data=GSS))
summary(GSStab)
@


\subsection{Converting among frequency tables and data frames}

As we've seen, a given contingency table can be represented 
equivalently in different forms,
but some \proglang{R} functions were designed for one particular representation.
\tabref{tab:convert} shows some handy tools for converting from one form to another.

\begin{table}[htb]
 \caption{Tools for converting among different forms for categorical data}\label{tab:convert}
 \begin{center}
   \begin{tabular}{llll}
	\hline
                 & \multicolumn{3}{c}{To this} \\
	From this      &     Case form         & Frequency form             &  Table form \\
	\hline
	Case form      &   noop                 & \verb|xtabs(~A+B)|        &  \verb|table(A,B)|  \\ 
	Frequency form &  \verb|expand.dft(X)|  & noop                      & \verb|xtabs(count~A+B)|\\
	Table form     &  \verb|expand.dft(X)|  & \verb|as.data.frame(X)|   &  noop \\
	\hline
   \end{tabular}
 \end{center}
\end{table}

A contingency table in table form (an object of \code{class(table)}) can be converted
to a data.frame with \codefun{as.data.frame}.%
\footnote{
Because \proglang{R} is object-oriented, this is actually a short-hand for
the function \codefun{as.data.frame.table}.
}  
The resulting
\code{data.frame} contains columns
representing the classifying factors and the table entries (as a column named by
the \code{responseName} argument, defaulting to \code{Freq}. This is the inverse of \codefun{xtabs}.

\emph{Example}: Convert the \code{GSStab} in table form to a data.frame in frequency form.
<<convert-ex1,results=verbatim>>=
as.data.frame(GSStab)
@

\emph{Example}: Convert the \code{Arthritis} data in case form to a 3-way table of
\code{Treatment} $\times$ \code{Sex} $\times$ \code{Improved}.%
\footnote{
Unfortunately, \codefun{table} does not allow a \code{data} argument to provide
an environment in which the table variables are to be found.  In the 
examples in \secref{sec:table} I used \code{attach(mydata)} for this purpose,
but \codefun{attach} leaves the variables in the global environment,
while \codefun{with} just evaluates the \codefun{table} expression in a
temporary environment of the data.
}
<<convert-ex2,results=verbatim>>=
Art.tab <-with(Arthritis, table(Treatment, Sex, Improved))
str(Art.tab)
ftable(Art.tab)
@


There may also be times that you wil need an equivalent case form \code{data.frame}
with factors  representing the table variables
rather than the frequency  table.
For example, the \codefun{mca} function in package \pkg{MASS}
only operates on data in this format. 
Marc Schwartz provided code for \codefun{expand.dft} on the  Rhelp
mailing list for converting a table back into a case form \code{data.frame}.
This function is included in \pkg{vcdExtra}.

\emph{Example}: Convert the \data{Arthritis} data in table form (\code{Art.tab}) back to a \code{data.frame}
in case form, with factors
\code{Treatment}, $\times$ \code{Sex} and \code{Improved}.
<<convert-ex3,results=verbatim>>=
Art.df <- expand.dft(Art.tab)
str(Art.df)
@

\subsection{A complex example}\label{sec:complex}

If you've followed so far, you're ready for a more complicated example.
The data file, \code{tv.dat} represents a 4-way table of size
$5 \times 11 \times 5 \times 3$ where the table variables (unnamed in the file)
are read as \code{V1} -- \code{V4}, and the cell frequency is read
as \code{V5}.  The file, stored in the \code{data/} directory
of \pkg{vcdExtra}, can be read as follows:
<<tv1,results=verbatim>>=
tv.data<-read.table(system.file("data","tv.dat",package="vcdExtra"))
head(tv.data,5)
@
For a local file, just use \codefun{read.table} in this form:
<<tv2,eval=FALSE>>=
tv.data<-read.table("C:/R/data/tv.dat")
@
The data \code{tv.dat} came from the initial implementation of 
mosaic displays in \proglang{R} by Jay Emerson. 
In turn, they came from the initial development of mosaic displays 
\citep{vcd:Hartigan+Kleiner:1984}
that illustrated the method with data on a large sample of TV viewers
whose behavior had been recorded for the Neilson ratings.
This data set contains sample television audience data from Neilsen
Media Research for the week starting November 6, 1995.

\begin{flushleft}
The table variables are:\\
~~\code{V1}-- values 1:5 correspond to the days Monday--Friday;\\
~~\code{V2}-- values 1:11 correspond to the quarter hour times 8:00PM through 10:30PM;\\
~~\code{V3}-- values 1:5 correspond to ABC, CBS, NBC, Fox, and non-network choices;\\
~~\code{V4}-- values 1:3 correspond to transition states: turn the television Off, Switch channels, 
 or Persist in viewing the current channel.
\end{flushleft}
	 
We are interested just the cell frequencies, and rely on the facts that the
(a) the table is complete--- there are no missing cells,
so \code{nrow(tv.data)}=\Sexpr{nrow(tv.data)};
(b) the observations are ordered so that \code{V1} varies most rapidly and
\code{V4} most slowly.  From this, we can just extract the frequency column
and reshape it into an array.
<<tv2,results=hide>>=
TV <- array(tv.data[,5], dim=c(5,11,5,3))                                        

dimnames(TV) <- list(c("Monday","Tuesday","Wednesday","Thursday","Friday"), 
                c("8:00","8:15","8:30","8:45","9:00","9:15","9:30",         
                "9:45","10:00","10:15","10:30"),                            
                c("ABC","CBS","NBC","Fox","Other"), c("Off","Switch","Persist"))
names(dimnames(TV))<-c("Day", "Time", "Network", "State")
@

But this table is too large and awkward to work with. Among the networks,
Fox and Other occur infrequently. 
We can also cut it down to a 3-way table by considering only viewers who persist
with the current station.
<<tv3,results=verbatim>>=
TV <- TV[,,1:3,]     # keep only ABC, CBS, NBC
TV <- TV[,,,3]       # keep only Persist -- now a 3 way table
structable(TV)
@

Finally, for some purposes, we might want to collapse the 11 times into a smaller number.
Here, we use \codefun{as.data.frame.table} to convert the table back to a data frame,
 \codefun{levels} to re-assign the values of \code{Time},
 and finally, \codefun{xtabs} to give a new, collapsed frequency table.

<<tv4,results=verbatim>>=
TV.df <- as.data.frame.table(TV)
levels(TV.df$Time) <- c(rep("8:00-8:59",4),rep("9:00-9:59",4), rep("10:00-10:44",3))
TV2 <- xtabs(Freq ~ Day + Time + Network, TV.df)
structable(Day ~ Time+Network,TV2)
@
Whew!


\section{Tests of Independence}

\subsection{CrossTable}

OK, now we're ready to do some analyses.  For tabular displays,
the  \codefun{CrossTable}  function in  the \pkg{gmodels}  package produces  cross-tabulations
modeled after \code{PROC FREQ} in \proglang{SAS} or \code{CROSSTABS} in \proglang{SPSS}. 
It has a wealth of options for the quantities that can be shown in each cell.

<<xtabs-ex2, results=verbatim>>=
# 2-Way Cross Tabulation
library(gmodels)
CrossTable(GSStab,prop.t=FALSE,prop.r=FALSE,prop.c=FALSE)
@
There are  options to  report percentages  (row, column,  cell), specify decimal
places, produce Chi-square,  Fisher, and McNemar  tests of independence,  report
expected  and residual  values (pearson,  standardized, adjusted  standardized),
include missing values as valid, annotate with row and column titles, and format
as \proglang{SAS} or \proglang{SPSS} style output! See \code{help(CrossTable)} for details.


\subsection{Chi-square test}

For 2-way tables you can use \codefun{chisq.test} to test independence of the row
and column variable. By default,  the $p$-value is calculated from  the asymptotic
chi-squared distribution of the test  statistic. Optionally, the $p$-value can  be
derived via Monte Carlo simulation. 

<<chisq,results=verbatim>>=
(HairEye <- margin.table(HairEyeColor, c(1, 2)))
chisq.test(HairEye)
@

\subsection{Fisher Exact Test}

\code{fisher.test(X)} provides an  exact test of  independence. \code{X} must be  a two-way
contingency table in table form.  Another form, 
\code{fisher.test(X, Y)} takes two
categorical vectors of the same length.  
For tables larger than $2 \times 2$ the method can be computationally intensive (or can fail) if
the frequencies are not small.

<<fisher,results=verbatim>>=
fisher.test(GSStab)
@

But this does not work because \data{HairEye} data has $n$=592 total frequency.
An exact test is unnecessary in this case.
<<echo=TRUE,eval=FALSE>>=
fisher.test(HairEye)
@
<<echo=FALSE,eval=TRUE,results=verbatim>>=
cat(try(fisher.test(HairEye)))
@

\subsection{Mantel-Haenszel test and conditional association}\label{sec:mantel}

Use the  \code{mantelhaen.test(X)} function  to perform  a Cochran-Mantel-Haenszel 
$\chi^2$ chi
test  of   the  null  hypothesis   that  two  nominal   variables  are
\emph{conditionally independent}, $A \perp B \given C$, in each stratum,  assuming that there is no  three-way
interaction. \code{X} is  a 3 dimensional  contingency table, where  the last dimension
refers to the strata.

The \data{UCBAdmissions} serves as an example of a $2 \times 2 \times 6$ table,
with \code{Dept} as the stratifying variable.
<<mantel1,results=verbatim>>=
## UC Berkeley Student Admissions
mantelhaen.test(UCBAdmissions)
@
The results show no evidence for association between admission and gender
when adjusted for department.  However, we can easily see that the assumption
of equal association across the strata (no 3-way association) is probably
violated. For $2 \times 2 \times k$ tables, this can be examimed
from the odds ratios for each $2 \times 2$ table (\codefun{oddsratio}), and
tested 
by  using
\verb|woolf_test()| in \pkg{vcd}.

%<<mantel2,results=verbatim>>=
%oddsRatio <- function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1])
%apply(UCBAdmissions, 3, oddsRatio)
%
%woolf_test(UCBAdmissions) 
%@ 
<<mantel2,results=verbatim>>=
oddsratio(UCBAdmissions, log=FALSE)
lor <- oddsratio(UCBAdmissions)  # capture log odds ratios
summary(lor)
woolf_test(UCBAdmissions) 
@ 
We  can visualize the  odds ratios of  Admission for
each  department  with  fourfold  displays  using  \codefun{fourfold}.  The cell
frequencies $n_{ij}$  of each  $2 \times  2$ table  are shown  as a  quarter circle whose
radius is proportional to $\sqrt{n_{ij}}$, so  that its area is proportional to  the
cell frequency.
Confidence rings for the odds ratio allow a visual test of the null of no association; 
the rings for adjacent quadrants overlap \emph{iff} the observed counts are consistent 
with the null hypothesis.  In the extended version (the default), brighter colors
are used where the odds ratio is significantly different from 1.
The following lines produce \figref{fig:fourfold1}.%
\footnote{The color values \code{col[3:4]} were modified from their default values
to show a greater contrast between significant and insignifcant associations here.}
<<fourfold1,fig=TRUE,height=6,width=9,results=hide,include=FALSE>>=
col <- c("#99CCFF", "#6699CC", "#F9AFAF", "#6666A0", "#FF0000", "#000080")
fourfold(UCB,mfrow=c(2,3), color=col)
@
 
%\setkeys{Gin}{width=0.8\textwidth}
\begin{figure}[htb]
\begin{center}
%<<fourfold1,fig=TRUE,height=6,width=9,results=hide>>=
%col <- c("#99CCFF", "#6699CC", "#F9AFAF", "#6666A0", "#FF0000", "#000080")
%fourfold(UCB,mfrow=c(2,3), color=col)
%@
\includegraphics[width=0.8\textwidth,trim=80 50 80 50]{fig/vcd-tut-fourfold1}
\caption{Fourfold display for the \data{UCBAdmissions} data. Where the odds ratio differs
	significantly from 1.0, the confidence bands do not overlap, and the circle quadrants are
	shaded more intensely.}
\label{fig:fourfold1}
\end{center}
\end{figure}

Another \pkg{vcd} function, \codefun{cotabplot}, provides a more general approach
to visualizing conditional associations in contingency tables,
similar to trellis-like plots produced by \codefun{coplot} and lattice graphics.
The \code{panel} argument supplies a function used to render each conditional 
subtable. The following gives a display (not shown) similar to \figref{fig:fourfold1}.
<<fourfold2,eval=FALSE>>=
cotabplot(UCB, panel = cotab_fourfold)
@

Finally, the there is a \codefun{plot} method for \code{oddsratio} objects.
By default, it shows the 95\% confidence interval for the log odds ratio.
\figref{fig:oddsratio} is produced by:
<<oddsratio0,eval=FALSE>>=
plot(lor, xlab="Department", ylab="Log Odds Ratio (Admit | Gender)")
@

\setkeys{Gin}{width=0.4\textwidth}
\begin{figure}[htb]
\begin{center}
<<oddsratio,fig=TRUE,height=6,width=6,echo=FALSE>>=
plot(lor, xlab="Department", ylab="Log Odds Ratio (Admit | Gender)")
@
\caption{Log odds ratio plot for the \data{UCBAdmissions} data.}
\label{fig:oddsratio}
\end{center}
\end{figure}
\subsection{Measures of Association}

There are a variety of statistical measures of \emph{strength} of association for
contingency tables--- similar in spirit to $r$ or $r^2$ for continuous variables.
With a large sample size, even a small degree of association can show a 
significant $\chi^2$, as in the example below for the \data{GSS} data.

The  \codefun{assocstats}  function in \pkg{vcd}  calculates  the   $\phi$
coefficient,  contingency coefficient,  and Cramer's  V for  an $r \times c$  table. 
The input must be in table form, a two-way $r \times c$ table.  
It won't work with \data{GSS} in frequency form, but by now you should know how
to convert.
<<assoc1,results=verbatim>>=
assocstats(GSStab)
@

A web article by Richard Darlington,
\url{http://www.psych.cornell.edu/Darlington/crosstab/TABLE0.HTM}
gives further description of these and other measures of association.

\subsection{Measures of Agreement}
The
\codefun{Kappa} function in the vcd package calculates Cohen's $\kappa$ and weighted
$\kappa$ for a square two-way table with the same row and column categories \citep{Cohen:60}.%
\footnote{ 
Don't confuse this with \codefun{kappa} in base \proglang{R} that computes something
entirely different (the condition number of a matrix).
}
Normal-theory $z$-tests can be obtained by dividing $\kappa$ by its asymptotic standard
error (ASE).
<<kappa,results=verbatim>>=
(K <- Kappa(SexualFun))
(Z <- K$Weighted[1]/K$Weighted[2])
@

A visualization of agreement, both unweighted and weighted for degree of departure
from exact agreement is provided by the \codefun{agreementplot} function.
\figref{fig:agreesex} shows the agreementplot for the \data{SexualFun} data,
produced as shown below. The Bangdiwala measures represent the proportion of the
shaded areas of the diagonal rectangles, using weights $w_1$ for exact agreement,
and $w_2$ for partial agreement one step from the main diagonal.
<<agreesex,fig=TRUE,height=6,width=7,results=verbatim,include=FALSE>>=
agree <- agreementplot(SexualFun, main="Is sex fun?")
unlist(agree)
@

%\setkeys{Gin}{width=0.5\textwidth}
\begin{figure}[htb]
\begin{center}
%<<agreesex,fig=TRUE,height=6,width=7,results=verbatim>>=
%agree <- agreementplot(SexualFun, main="Is sex fun?")
%agree
%@
\includegraphics[width=0.4\textwidth,trim=50 25 50 25]{fig/vcd-tut-agreesex}
\caption{Agreement plot for the \data{SexualFun} data.}
\label{fig:agreesex}
\end{center}
\end{figure}
In other examples, the agreement plot can help to show \emph{sources}
of disagreement.  For example, when the shaded boxes are above or below the diagonal
(red) line, a lack of exact agreement can be attributed in part to
different frequency of use of categories by the two raters-- lack of
\emph{marginal homogeneity}.
	
\subsection{Correspondence analysis}
Use the \pkg{ca} package for correspondence analysis for visually exploring relationships
between rows and columns in contingency tables.  For an $r \times c$ table,
the method provides a breakdown of the Pearson $\chi^2$ for association in up to $M = \min(r-1, c-1)$
dimensions, and finds scores for the row ($x_{im}$) and column ($y_{jm}$) categories
such that the observations have the maximum possible correlations.


Here, we carry out a simple correspondence analysis of the \data{HairEye} data.
The printed results show that nearly 99\% of the association between hair color and eye color
can be accounted for in 2 dimensions.
<<ca1,results=verbatim>>=
library(ca)
ca(HairEye)
@

The resulting \code{ca} object can be plotted just by running the \codefun{plot}
method on the \code{ca} object, giving the result in
\figref{fig:ca-haireye}.  \codefun{plot.ca} does not allow labels for dimensions;
these can be added with \codefun{title}.
It can be seen that most of the association is accounted for by the ordering
of both hair color and eye color along Dimension 1, a dark to light dimension.
<<ca-haireye0,echo=TRUE,eval=FALSE>>=
plot(ca(HairEye), main="Hair Color and Eye Color")
title(xlab="Dim 1", ylab="Dim 2")
@

\setkeys{Gin}{width=0.7\textwidth}
\begin{figure}[htb]
\begin{center}
<<ca-haireye,results=hide,fig=TRUE,echo=FALSE>>=
plot(ca(HairEye), main="Hair Color and Eye Color")
title(xlab="Dim 1", ylab="Dim 2")
@
\caption{Correspondence analysis plot for the \data{HairEye} data.}
\label{fig:ca-haireye}
\end{center}
\end{figure}

\section{Loglinear Models}

You can  use the  \codefun{loglm}  function in  the \pkg{MASS}  package to fit log-linear
models.  Equivalent models can also be fit (from a different perspective) as generalized
linear models with the \codefun{glm}  function using the \code{family='poisson'} argument,
and the \pkg{gnm} package provides a wider range of generalized \emph{nonlinear} models,
particularly for testing structured associations.
The visualization methods for these models are most advanced for models fit using \codefun{loglm},
so this approach is emphasized here.

Assume we  have a 3-way  contingency table based  on
variables A, B, and C.  
The possible different forms of \loglin\ models for a 3-way table are shown in \tabref{tab:loglin-3way}.
The \textbf{Model formula} column shows how to express each model in \proglang{R}.
In the \textbf{Interpretation} column, the symbol ``$\perp$'' is to be read as ``is independent of,''
and ``$\given$'' means ``conditional on,'' or ``adjusting for,'' or just ``given''.

\begin{table}[htb]
 \caption{Log-linear Models for Three-Way Tables}\label{tab:loglin-3way}
 \begin{center}
 \begin{tabular}{llll}
  \hline
  \textbf{Model}           & \textbf{Model formula}  & \textbf{Symbol}& \textbf{Interpretation} \\
  \hline\hline 
  Mutual independence      & \verb|~A + B + C|       & $[A][B][C]$    & $A \perp B \perp C$ \\ 
  Joint independence       & \verb|~A*B + C|         & $[AB][C]$      & $(A \: B) \perp C$ \\ 
  Conditional independence & \verb|~(A+B)*C|         & $[AC][BC]$     & $(A \perp B) \given C$ \\ 
  All two-way associations & \verb|~A*B + A*C + B*C| & $[AB][AC][BC]$ & homogeneous association  \\ 
  Saturated model          & \verb|~A*B*C|           & $[ABC]$        & 3-way association \\ 
  \hline
 \end{tabular}
 \end{center}
\end{table}



For example, the formula \verb|~A + B + C| specifies the model of mutual independence with
no associations among the three factors.  In standard notation for the expected frequencies
$m_{ijk}$, this corresponds to
\begin{equation*}
	\log ( m_{ijk} ) = \mu + \lambda_i^A + \lambda_j^B + \lambda_k^C \equiv \texttt{A + B + C}
\end{equation*}
The parameters $\lambda_i^A , \lambda_j^B$ and  $\lambda_k^C$ pertain to the differences among the
one-way marginal frequencies for the factors A, B and C. 

Similarly, the model of joint independence allows an association between A and B, but specifies that
C is independent of both of these and their combinations,
\begin{equation*}
	\log ( m_{ijk} ) = \mu + \lambda_i^A + \lambda_j^B + \lambda_k^C + \lambda_{ij}^{AB} \equiv \texttt{A * B + C}
\end{equation*}

In the literature or text books, you will often find these models expressed in shorthand symbolic notation,
using brackets, \texttt{[ ]} to enclose the \emph{high-order terms} in the model.
Thus, the joint independence model can be denoted \texttt{[AB][C]}, as shown in the Symbol column in 
\tabref{tab:loglin-3way}.


\subsection[Fitting with loglm()]{Fitting with \codefun{loglm}}\label{sec:loglm}
For example, we can fit the model of mutual independence among hair color, eye color and sex 
in \data{HairEyeColor} as

<<loglm-hec1,results=verbatim>>=
library(MASS)
## Independence model of hair and eye color and sex.  
hec.1 <- loglm(~Hair+Eye+Sex, data=HairEyeColor)
hec.1
@

Similarly, the models of conditional independence and joint independence are specified as
<<loglm-hec2,results=verbatim>>=
## Conditional independence
hec.2 <- loglm(~(Hair + Eye) * Sex, data=HairEyeColor)
hec.2
@
<<loglm-hec3,results=verbatim>>=
## Joint independence model.  
hec.3 <- loglm(~Hair*Eye + Sex, data=HairEyeColor)
hec.3
@
Note that printing the model gives a brief summary of the goodness of fit.
A set of models can be compared using the \codefun{anova} function.

<<loglm-anova,results=verbatim>>=
anova(hec.1, hec.2, hec.3)
@

%Martin Theus and Stephan Lauer have written an excellent article on  Visualizing
%Loglinear Models, using  mosaic plots. There  is also great  tutorial example by
%Kevin Quinn on analyzing loglinear models via glm.


\section{Mosaic plots}\label{sec:mosaic}

Mosaic plots provide an ideal method both for visualizing contingency tables and for 
visualizing the fit--- or more importantly--- lack of fit of a \loglin\ model.
For a two-way table, \codefun{mosaic} fits a model of independence, $[A][B]$
or \verb|~A+B| as an \proglang{R} formula.
For $n$-way tables, \codefun{mosaic} can fit any \loglin\ model, and can also be
used to plot a model fit with \codefun{loglm}.
See \citet{vcd:Friendly:1994,vcd:Friendly:1999} for the statistical ideas behind these
uses of mosaic displays in connection with \loglin\ models.

The essential idea is to recursively sub-divide a unit square into rectangular ``tiles'' for the
cells of the table, such
that the are area of each tile is proportional to the cell frequency.
For a given \loglin\ model, the tiles can then be shaded in various ways to reflect
the residuals (lack of fit) for a given model.  The pattern of residuals can then
be used to suggest a better model or understand \emph{where} a given model fits or
does not fit.

\codefun{mosaic} provides a wide range of options for the directions of splitting,
the specification of shading, labeling, spacing, legend and many other details.
It is actually implemented as a special case of a more general
class of displays for $n$-way tables called \code{strucplot}, including
sieve diagrams, association plots, double-decker plots as well as mosaic
plots.  For details, see \code{help(strucplot)} and the ``See also'' links,
and also \citet{vcd:Meyer+Zeileis+Hornik:2006b}, which is available as
an \proglang{R} vignette via \code{vignette("strucplot", package="vcd")}.

\figref{fig:arthritis}, showing the association between
\code{Treatment} and \code{Improved} was produced with the following
call to \codefun{mosaic}.
<<Arthritis1,echo=TRUE,eval=FALSE>>=
mosaic(art, gp = shading_max, split_vertical = TRUE, 
       main="Arthritis: [Treatment] [Improved]")
@
Note that the residuals for the independence model were not large
(as shown in the legend),
yet the association between \code{Treatment} and \code{Improved}
is highly significant.
<<art1,results=verbatim>>=
summary(art)
@
In contrast, one of the other shading schemes, from \citet{vcd:Friendly:1994}
(use: \verb|gp = shading_Friendly|), 
uses fixed cutoffs of $\pm 2, \pm 4$,
to shade cells which are \emph{individually} significant
at approximately $\alpha = 0.5$ and $\alpha = 0.001$ levels, respectively.
The right panel below uses \verb|gp = shading_Friendly|.

\setkeys{Gin}{width=0.5\textwidth}
<<art21,fig=TRUE,height=6,width=7,echo=FALSE>>=
mosaic(art, gp = shading_max, split_vertical = TRUE, 
       main="Arthritis: gp = shading_max")
@
<<art22,fig=TRUE,height=6,width=7,echo=FALSE>>=
mosaic(art, gp = shading_Friendly, split_vertical = TRUE, 
       main="Arthritis: gp = shading_Friendly")
@

\subsection[Mosaics for loglinear models]{Mosaics for \loglin\ models}\label{sec:mosaic-llm}

When you have fit a \loglin\ model using \codefun{loglm}, 
and saved the result (as a \code{loglm} object) the simplest way to display the
results is to use the \codefun{plot} method for the \code{loglm} object.
Calling \code{mosaic(loglm.object)} has the same result.
In \secref{sec:loglm} above, we fit several different models to the
\data{HairEyeColor} data.  We can produce mosaic displays of each just
by plotting them:

<<hec-mosaic,eval=FALSE>>=
# mosaic plots, using plot.loglm() method
plot(hec.1, main="model: [Hair][Eye][Sex]")
plot(hec.2, main="model: [HairSex][EyeSex]")
plot(hec.3, main="model: [HairEye][Sex]")
@

\setkeys{Gin}{width=0.32\textwidth}
<<hec1,fig=TRUE,height=6,width=7,echo=FALSE>>=
plot(hec.1, main="model: [Hair][Eye][Sex]")
@
<<hec2,fig=TRUE,height=6,width=7,echo=FALSE>>=
plot(hec.2, main="model: [HairSex][EyeSex]")
@
<<hec3,fig=TRUE,height=6,width=7,echo=FALSE>>=
plot(hec.3, main="model: [HairSex][EyeSex]")
@

Alternatively, you can supply the model formula to \codefun{mosaic}
with the \code{expected} argument.  This is passed to \codefun{loglm},
which fits the model, and returns residuals used for shading in the plot. 

For example, here we examine the \data{TV2} constructed in \secref{sec:complex}
above.  The goal is to see how Network choice depends on (varies with)
Day and Time. To do this: 
\begin{itemize}
	\item We fit a model of joint independence of
\code{Network} on the combinations of \code{Day} and \code{Time},
with the model formula \verb|~Day:Time + Network|.
  \item To make the display more easily read, we place \code{Day} and \code{Time}
on the vertical axis and \code{Network} on the horizontal,
  \item The \code{Time} values overlap on the right vertical axis, so we use
  \codefun{level} to abbreviate them.  \codefun{mosaic} also supports a 
  more sophisticated set of labeling functions.  Instead of changing the data
  table, we could have used 
  \verb|labeling_args = list(abbreviate = c(Time = 2))| for a similar effect.
\end{itemize}

The following call to \codefun{mosaic} produces \figref{fig:TV-mosaic}
<<TV-mosaic0,eval=FALSE>>=
dimnames(TV2)$Time <- c("8", "9", "10")     # re-level for mosaic display
mosaic(~ Day + Network + Time, data=TV2, expected=~Day:Time + Network, 
         legend=FALSE, gp=shading_Friendly)
@

\setkeys{Gin}{width=0.75\textwidth}
\begin{figure}[htb]
\begin{center}
<<TV-mosaic,fig=TRUE,height=6,width=6,echo=FALSE>>=
dimnames(TV2)$Time <- c("8", "9", "10")     # re-level for mosaic display
mosaic(~ Day + Network + Time, data=TV2, expected=~Day:Time + Network, 
         legend=FALSE, gp=shading_Friendly)
@
\caption{Mosaic plot for the \data{TV} data
	showing model of joint independence, \texttt{Day:Time + Network} .}
\label{fig:TV-mosaic}
\end{center}
\end{figure}

From this, it is easy to read from the display how network choice varies with day and
time. For example, CBS dominates in all time slots on Monday;
ABC and NBC dominate on Tuesday, particularly in the later time slots;
Thursday is an NBC day, while on Friday, ABC gets the greatest share.

In interpreting this mosaic and other plots, it is important to understand that
associations included in the model---here, that between day and time---are \emph{not}
shown in the shading of the cells, because they have been fitted (taken into account)
in the \loglin\ model. 

For comparison, you might want to try fitting the model of homogeneous association.
This allows all pairs of factors to be associated, but asserts that each pairwise
association is the same across the levels of the remaining factor.
The resulting plot displays the contributions to a 3-way association, but is not shown here.
<<TV-mosaic1,eval=FALSE>>=
mosaic(~ Day + Network + Time, data=TV2, 
         expected=~Day:Time + Day:Network + Time:Network, 
         legend=FALSE, gp=shading_Friendly)
@

\section[Continuous predictors]{Continuous predictors: spine and conditional density plots}
When continuous predictors are available---and potentially important--- in explaining a
categorical outcome, models for that outcome include:
logistic regression (binary response), 
the proportional odds model (ordered polytomous response),
multinomial (generalized) logistic regression.
Many of these are special cases of the generalized linear model using the
\code{"poisson"} or \code{"binomial"} family and their relatives.

I don't go into fitting such models here, but I would be remiss not to illustrate some
visualizations in \pkg{vcd} that are helpful here.
The first of these is the spine plot or spinogram \citep{vcd:Hummel:1996}
 (produced with \codefun{spine}).
These are special cases of mosaic plots with 
specific spacing and shading to show how a categorical response varies with
a continuous or categorical predictor.

They are also a generalization of stacked bar plots where not the heights  but
the \emph{widths} of the bars corresponds to the relative frequencies of \code{x}. The heights
of the  bars then  correspond to  the conditional  relative frequencies  of {y} in
every \code{x} group.

For the \data{Arthritis} data, we can see how \code{Improved} varies with \code{Age}
as follows.  \codefun{spine} takes a formula of the form 
\verb|y ~ x| with a single dependent factor and a single explanatory variable \code{x}
(a numeric variable or a factor).
The range of a numeric variable\code{x} is divided into intervals based on the
\code{breaks} argument, and stacked bars are drawn to show the distribution of
\code{y} as \code{x} varies.  As shown below, the discrete table that is visualized
is returned by the function.

<<spine1,fig=FALSE,results=verbatim>>=
(spine(Improved ~ Age, data = Arthritis, breaks = 3))
(spine(Improved ~ Age, data = Arthritis, breaks = "Scott"))
@

\setkeys{Gin}{width=0.49\textwidth}
<<spine2,fig=TRUE,echo=FALSE,height=6,width=6>>=
(spine(Improved ~ Age, data = Arthritis, breaks = 3))
@
<<spine3,fig=TRUE,echo=FALSE,height=6,width=6>>=
(spine(Improved ~ Age, data = Arthritis, breaks = "Scott"))
@


The conditional density plot \citep{vcd:Hofmann+Theus} is a further generalization.
This visualization technique is similar to spinograms, but uses a smoothing approach
rather than discretizing the explanatory variable.  As well, it uses 
the original \code{x} axis and not a distorted one.

\setkeys{Gin}{width=0.6\textwidth}
\begin{figure}[htb]
\begin{center}
<<cdplot,fig=TRUE,height=6,width=6>>=
cdplot(Improved ~ Age, data = Arthritis)
with(Arthritis, rug(jitter(Age), col="white", quiet=TRUE))
@
\caption{Conditional density plot for the \data{Arthritis} data
	showing the variation of Improved with Age.}
\label{fig:cd-plot}
\end{center}
\end{figure}

In such plots, it is useful to also see the distribution of the observations
across the horizontal axis, e.g., with a \codefun{rug} plot.
\figref{fig:cd-plot} uses \codefun{cdplot} from the \pkg{graphics} package
rather than \verb|cd_plot()| from \pkg{vcd}, and is produced with
<<cdplot1,echo=TRUE>>=
cdplot(Improved ~ Age, data = Arthritis)
with(Arthritis, rug(jitter(Age), col="white", quiet=TRUE))
@
From \figref{fig:cd-plot} it can be easily seen that the proportion
of patients reporting Some or Marked improvement increases with Age,
but there are some peculiar bumps in the distribution.
These may be real or artifactual, but they would be hard to see
with most other visualization methods.
When we switch from non-parametric data exploration to parametric
statistical models, such effects are easily missed.

\bibliography{vcd,vcdExtra}

\end{document}
